# ğŸ“š RAG + GraphRAG + HyDE QA Chatbot

This project is a **Retrieval-Augmented Generation (RAG)** based **Question-Answering Chatbot** with a **Streamlit** interface, now enhanced with **GraphRAG** and **HyDE (Hypothetical Document Embeddings)**.  
Users can upload **PDF** or **DOCX** files; the app extracts text, stores embeddings in **FAISS**, builds a knowledge graph, and generates **context-aware answers** using a **Hugging Face** model augmented with HyDE.

---

## âœ¨ Features

* ğŸ“‚ **File Upload:** Upload multiple PDF/DOCX documents  
* ğŸ§© **Text Processing:** Cleaning + chunking  
* ğŸ” **Search Engine:** FAISS + optional BM25 hybrid retrieval  
* ğŸ¤– **RAG Pipeline:** Hugging Face *Flan-T5* for context-aware answers  
* ğŸ§  **GraphRAG Pipeline:** Knowledge graph construction and reasoning from uploaded documents  
* ğŸ’­ **HyDE Support:** Generates hypothetical documents to improve answers in low-data scenarios  
* ğŸ” **Cache:** Disk-based caching (`shelve`) for faster repeated queries  
* ğŸ·ï¸ **Metadata:** Responses include document names for traceability  
* ğŸ”‘ **Authentication:** Simple username/password login via environment variables  
* ğŸ³ **Dockerized:** Easy to build and deploy  

---

## ğŸš€ Quick Start (Local)

### 1ï¸âƒ£ Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate
````

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the Streamlit app

```bash
streamlit run main.py
```

### 4ï¸âƒ£ Default login credentials

```
Username: admin
Password: password
```

> To override credentials, set environment variables:

```bash
export APP_USER=your_username
export APP_PASS=your_password
```

Open your browser at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ³ Running with Docker

### Build and start containers

```bash
docker-compose up -d --build
```

### Stop containers

```bash
docker-compose down
```

Open your browser at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“‚ Project Structure

```text
app/
â”œâ”€â”€ file_processor.py      # File parsing & chunking
â”œâ”€â”€ vectorstore.py         # FAISS wrapper
â”œâ”€â”€ rag_pipeline.py        # Retrieval + generation pipeline + cache
â”œâ”€â”€ graph_builder.py       # Extract entities & relations from text
â”œâ”€â”€ graph_pipeline.py      # GraphRAG: integrate knowledge graph with RAG pipeline
â”œâ”€â”€ hyde_pipeline.py       # HyDE: generate hypothetical documents for better answers
â”œâ”€â”€ utils.py               # Helper functions
main.py                    # Streamlit UI entry point
Dockerfile                 # Docker image definition
docker-compose.yml         # Multi-container orchestration
.env                       # Environment variables (user credentials)
requirements.txt           # Python dependencies
```

---

## âš™ï¸ Environment Variables

| Variable         | Description                             | Default    |
| ---------------- | --------------------------------------- | ---------- |
| `APP_USER`       | Username for login                      | `admin`    |
| `APP_PASS`       | Password for login                      | `password` |
| `OPENAI_API_KEY` | (Optional) Key for enhanced model usage | -          |

---

## ğŸ§  Tech Stack

* Python 3.10+
* Streamlit
* FAISS
* Hugging Face Transformers
* spaCy (entity extraction)
* NetworkX (graph building & querying)
* Docker / Docker Compose

---

## ğŸ§ª Example Usage

1. Upload one or more `.pdf` or `.docx` files.
2. Ask a question about the content (e.g., *"Summarize the introduction section"*).
3. The chatbot retrieves relevant context:

   * **RAG:** via vector embeddings (FAISS + optional BM25)
   * **GraphRAG:** leverages related entities for complex reasoning
   * **HyDE:** generates hypothetical documents to fill gaps when explicit answers are missing
4. The app produces context-aware answers using Hugging Face *Flan-T5*.

---

## ğŸ§  GraphRAG Usage

* Enable **Knowledge Graph** in the sidebar.
* Click **Build Knowledge Graph** to extract entities and relations from uploaded documents.
* GraphRAG improves retrieval for multi-step reasoning and complex queries.

---

## ğŸ’¡ HyDE Usage

* Integrated into the RAG pipeline.
* Generates hypothetical documents based on the query to improve answer quality.
* Especially useful for low-data or incomplete document scenarios, providing a seamless contextual response.

---

## ğŸ¤ Contributing

Contributions are welcome!
Please open an issue or submit a pull request for new features or bug fixes.

---

## ğŸ“œ License

This project is licensed under the **MIT License**.
See the [LICENSE](./LICENSE) file for details.

---

## ğŸ’¡ Acknowledgements

Special thanks to:

* [Hugging Face](https://huggingface.co/)
* [Streamlit](https://streamlit.io/)
* [FAISS](https://github.com/facebookresearch/faiss)
* [spaCy](https://spacy.io/)
* [NetworkX](https://networkx.org/)
